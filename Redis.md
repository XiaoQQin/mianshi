## 1.Redis为什么单线程还这么快？
1. Redis完全基于内存，绝大部分请求是纯粹的内存操作，执行效率高。  
2. Redis使用单进程单线程模型的(K,V)数据库，将数据存储在内存中，存取均不会受到硬盘IO的限制，因此其执行速度极快，另外单线程也能处理高并发请求，还可以避免频繁上下文切换和锁的竞争，如果  想要多核运行也可以启动多个实例。**Redis 6.0使用了多线程版本，Redis 的多线程部分只是用来处理网络数据的读写和协议解析，执行命令仍然是单线程**。   
3. 数据结构简单，对数据操作也简单，Redis不使用表，不会强制用户对各个关系进行关联，不会有复杂的关系限制，其存储结构就是键值对，类似于HashMap  
4. Redis使用多路I/O复用模型，为非阻塞IO
# 2.Redis五大数据类型
- String(字符串):String类似的使用场景,value除了是我们的字符串还可以是我们的数字。通常可以使用下面的场景
   - 计数器
   - 粉丝数
   - 对象缓存存储
- List(列表): 实际为一个链表。如果key 不存在，创建新的链表;如果key存在，新增内容。可以使用List作为队列或栈。
   - 队列 （Lpush Rpop）
   - 栈（Lpush Lpop）
- Set(集合):set中的值是不能重读的,有提供**SDIFF(差集)、SINTER(交集)、SUNION(并集)**这三种集合之间的操作
   - 共同关注：用户将所有关注的人放在一个set集合中！两个用户使用交集
   - 推荐好友：两个用户使用差集
-  Hash(哈希): Map集合，key-map! 时候这个值是一个map集合！ 本质和String类型没有太大区别，还是一个简单的key-vlaue。
   - 对象的存储
## Zset(有序集合)
   在set的基础上，**底层实现是跳表**。增加了一个值，```zset k1 score1 v1```,它有如下的用途
   - 排行榜Top的实现 
   - 带权重的排序    
     
     
   zset的底层数据结构有两种分为，**ziplist和skiplist**。在同时满足以下两个条件的时候使用ziplist，其他时候使用skiplist，两个条件如下：
   - 有序集合保存的元素数量小于128个
   - 有序集合保存的所有元素的长度小于64字节
## 3.三种特殊数据类型
-  Geospatial(地理位置)：存储地理信息，**底层就是zet**
   - 朋友定位，附近的人，打车距离计算
-  Hyperloglog(基数):指不重复的数。数据集 {1, 3, 5, 7, 5, 7, 8}， 那么这个数据集的基数集为 {1, 3, 5 ,7, 8}, 基数(不重复元素)为5。用作超大数额的计数，即我们只关注计数。0.81% 错误率。
   - 统计UV任务：即网页每日独立访客
-  Bitmap(位图)：一种数据结构，都是操作二进制位来进行记录，就只有0 和 1 两个状态！统计用户信息，活跃，不活跃！ 登录 、 未登录！ 打卡，365打卡！ 两个状态的，都可以使用。

## 关于跳表
跳跃表：可以简称为跳表，它是一种多层链表。跳跃表插入数据的时间复杂度为**O(logn)**,删除数据时间复杂度为**O(logn)**,空间复杂度为**O(n)**.它是zset的底层数据结构之一。
## 4.事务
Redis事务本质：一组命令的集合！ 一个事务中的所有命令都会被序列化，在事务执行过程的中，会按照顺序执行。所有的命令在事务中，并没有直接被执行！只有发起执行命令的时候才会执行！Exec  
**Redis事务没有隔离级别的概念，Redis单条命令式保存原子性的，但是事务不保证原子性**。  
- 开启事务(multi)  
- 命令入队
- 执行事务(exec)
### 事务有两种异常  
- 编译型异常（代码有问题！ 命令有错！),事务中所有的命令都不会被执行。
   ```
   127.0.0.1:6379> multi
   OK
   127.0.0.1:6379> set k1 v1
   QUEUED
   127.0.0.1:6379> set k2 v2
   QUEUED
   127.0.0.1:6379> set k3 v3
   QUEUED
   127.0.0.1:6379> getset k3   #错误的命令
   (error) ERR wrong number of arguments for 'getset' command
   127.0.0.1:6379> set k4 v4
   QUEUED
   127.0.0.1:6379> set k5 v5
   QUEUED
   127.0.0.1:6379> exec  #执行事务会报错
   (error) EXECABORT Transaction discarded because of previous errors.
   127.0.0.1:6379> get k5    #所有事务都不会执行成功
   (nil)
   127.0.0.1:6379> 
   ```
- 运行时异常(1/0)：， 如果事务队列中存在语法性，那么执行命令的时候，其他命令是可以正常执行的，错误命令抛出异常！
   ```
   127.0.0.1:6379> set k1 "v1"
   OK
   127.0.0.1:6379> multi
   OK
   127.0.0.1:6379> incr k1    #执行时才会失败
   QUEUED
   127.0.0.1:6379> set k2 v2
   QUEUED
   127.0.0.1:6379> set k3 v3
   QUEUED
   127.0.0.1:6379> get k3
   QUEUED
   127.0.0.1:6379> exec
   1) (error) ERR value is not an integer or out of range  #虽然第一条命令报错了，但事务仍正常执行，其他事务执行成功
   2) OK
   3) OK
   4) "v3"
   127.0.0.1:6379> get k2
   "v2"
   127.0.0.1:6379> get k3
   "v3"
   127.0.0.1:6379> 
   ```
## redis的过期策略以及内存淘汰机制
redis采用的是**定期删除+惰性删除策略**。
为什么不用定时删除策略?定时删除,用一个定时器来负责监视key,过期则自动删除。虽然内存及时释放，但是十分消耗CPU资源。在大并发请求下，CPU要将时间应用在处理请求，而不是删除key,因此没有采用这一策略.  

### 定期删除+惰性删除是如何工作
定期删除，redis默认每个100ms检查，是否有过期的key,有过期key则删除。需要说明的是，redis不是每个100ms将所有的key检查一次，而是**随机抽取进行检查**(如果每隔100ms,全部key进行检查，redis岂不是卡死)。因此，如果只采用定期删除策略，会导致很多key到时间没有删除。于是，惰性删除派上用场。也就是说在你获取某个key的时候，redis会检查一下，这个key如果设置了过期时间那么是否过期了？如果过期了此时就会删除。
### 定期删除+惰性删除产生的问题
不是的，如果定期删除没删除key。然后你也没即时去请求key，也就是说惰性删除也没生效。这样，redis的内存会越来越高。那么就应该采用内存淘汰机制。

### 内存淘汰机制
- volatile-lru：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰
- volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰
- volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰
- volatile-lfu：从已设置过期时间的数据集(server.db[i].expires)中挑选最不经常使⽤的数据淘汰
- allkeys-lru：从数据集（server.db[i].dict）中挑选最近最少使用的数据淘汰
- allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰
- allkeys-lfu：当内存不⾜以容纳新写⼊数据时，在键空间中，移除最不经常使⽤的key
## 5.Redis持久化
Redis是内存数据库，如果不将内存中的数据库状态保存到磁盘，那么一旦服务器进程退出，服务器中的数据库状态也会消失。Redis有两种持久化方式。
### RDB    
在指定的时间间隔内将内存中的数据集快照写入磁盘,它恢复时是将快照文件直接读到内存里。RDB的触发方式有两种:**手动触发和自动触发**  
- **手动触发**
   -  **bgsave**:Redis会fork一个子进程，由子进程负责持久化过程
   -  **save**:会阻塞Redis服务器，直到持久化完成，如果bgsave命令保存数据的子进程发生错误时，用save是最后的手段，应当在**线上禁止使用**
- **自动触发**  
   -  根据我们的```save m n```配置规则自动触发  
   -  从节点复制时，主节点发送RDB文件给从节点完成复制操作，主节点会触发bgsave  
   -  执行```shutdown```时，如果没有aof,就会触发
#### 原理
   -  Redis调用fork,同时拥有一个父进程和子进程
   -  子进程将数据写入到一个临时RDB文件中 
   -  当子进程完成对新RDB文件的写入时，Redis用新的RDB文件覆盖原来的RDB文件，并且删除旧的RDB文件
   整个过程中，主进程是不进行任何IO操作的，这就确保了极高的性能
#### 优点  
     -  适合大规模的数据恢复
     -  对数据的完整性要不高
#### 缺点
     -  需要一定的时间间隔进程操作！如果redis意外宕机了，这个最后一次修改数据就没有的了
     -  fork进程的时候，会占用一定的内容空间
### AOF  
以日志的形式来记录每个写操作，将Redis执行过的所有指令记录下来（读操作不记录），只许追加文件但不可以改写文件，redis启动之初会读取该文件重新构建数据。
#### 原理  
AOF 重写和 RDB 创建快照一样，都巧妙地利用了写时复制机制
- Redis执行Fork,现在同时拥有父进程和子进程
- 子进程开始将AOF文件的内容写入到临时文件中
- 对于所有新执行的写入命令，父进程一边将它们累积到一个内存缓存中，一边将这些改动追加到现有AOF文件的末尾，这样即使在重写的中途发生停机，现有的aof文件也还是安全的
- 当子进程完成重写工作时，它给父进程发送一个信号，父进程在接收到信号后，将内存缓存中的所有数据追加到新AOF文件的末尾
- Redis 原子地用新文件替换旧文件，之后所有命令都会直接追加到新 AOF 文件的末尾
#### 优点
  -  每一次修改都同步，文件的完整会更加好
  -  每秒同步一次，效率很高
#### 缺点
  -  相对于数据文件来说，aof远远大于 rdb，修复的速度也比 rdb慢  
  -  Aof 运行效率也要比 rdb 慢，所以我们redis默认的配置就是rdb持久化
## 6.Redis主从复制  
主从复制，是指将一台Redis服务器的数据，复制到其他的Redis服务器。前者称为主节点(master/leader)，后者称为从节点(slave/follower)；数据的复制是单向的，只能由主节点到从节点。
Master以写为主，Slave 以读为主。  
可以使用**哨兵模式**,在主机宕机时，自动选择主机，保证服务不中断  
  
## 7.Redis高并发下问题 
### 7.1缓存穿透(查不到)  
缓存穿透的概念很简单，用户想要查询一个数据，发现redis内存数据库没有，也就是缓存没有命中，于是向持久层数据库查询。败。当用户很多的时候，缓存都没有命中（秒杀！），于是都去请求了持久层数据库。  
#### 解决方案
- **布隆过滤器**    
  布隆过滤器是一种数据结构，对所有可能查询的参数以hash形式存储，在控制层先进行校验，不符合则丢弃，从而避免了对底层存储系统的查询压力。  
  [详解布隆过滤器的原理、使用场景和注意事项](https://www.jianshu.com/p/2104d11ee0a2)
- **缓存空对象**  
  当存储层不命中后，即使返回的空对象也将其缓存起来，同时会设置一个过期时间，之后再访问这个数据将会从缓存中获取，保护了后端数据源
### 7.2 缓存击穿
   缓存击穿，是指一个key非常热点，在不停的扛着大并发，大并发集中对这一个点进行访问，当这个key在失效的瞬间，持续的大并发就穿破缓存，直接请求数据库，就像在一个屏障上凿开了一个洞
#### 解决方案
- **设置热点数据永不过期**  
  从缓存层面来看，没有设置过期时间，所以不会出现热点 key 过期后产生的问题。
- **分布式锁**  
  使用分布式锁，保证对于每个key同时只有一个线程去查询后端服务，其他线程没有获得分布式锁的权限，因此只需要等待即可
### 缓存雪崩  
缓存雪崩，是指在某一个时间段，缓存集中过期失效，Redis宕机。是所有的请求都会达到存储层，存储层的调用量会暴增，造成存储层也会挂掉的情
#### 解决方案  
-  **redis高可用**    
   这个思想的含义是，既然redis有可能挂掉，那我多增设几台redis，这样一台挂掉之后其他的还可以继续工作，其实就是搭建的集群
-  **限流降级**    
   在缓存失效后，通过加锁或者队列来控制读数据库写缓存的线程数量。比如对某个key只允许一个线程查询数据和写缓存，其他线程等待。  
-  **数据预热**    
   是在正式部署之前，我先把可能的数据先预先访问一遍，这样部分可能大量访问的数据就会加载到缓存中。在即将发生大并发访问前手动触发加载缓存不同的key，设置不同的过期时间，让缓存失效的时间 点尽量均匀
## 8.Redis解决Mysql数据一致性问题
### 最初级的缓存不一致问题及解决方案
**场景**: 当更新数据时，如更新某商品的库存，当前商品的库存是100，现在要更新为99，先更新数据库更改成99，然后删除缓存，发现删除缓存失败了，这意味着数据库存的是99，而缓存是100，这导致数据库和缓存不一致。  
  
  
这种情况应该是先删除缓存，然后在更新数据库，如果删除缓存失败，那就不要更新数据库，如果说删除缓存成功，而更新数据库失败，那查询的时候只是从数据库里查了旧的数据而已，这样就能保持数据库与缓存的一致性。 
  
### 更为复杂的数据不一致问题
**场景**：在高并发的情况下，如果当删除完缓存的时候，这时去更新数据库，但还没有更新完，另外一个请求来查询数据，发现缓存里没有，就去数据库里查，还是以上面商品库存为例，如果数据库中产品的库存是100，那么查询到的库存是100，然后插入缓存，插入完缓存后，原来那个更新数据库的线程把数据库更新为了99，导致数据库与缓存不一致的情况
  
遇到这种情况，可以用队列的去解决这个问，创建几个队列，如20个，根据商品的ID去做hash值，然后对队列个数取摸，当有数据更新请求时，先把它丢到队列里去，当更新完后在从队列里去除，如果在更新的过程中，遇到以上场景，先去缓存里看下有没有数据，如果没有，可以先去队列里看是否有相同商品ID在做更新，如果有也把查询的请求发送到队列里去，然后同步等待缓存更新完成。
  
## 9.Redis实现分布式锁
### 初级  
生成一个UUID当做是当前线程的标识，同时在Redis中使用**setnx和expire结合的set方法**设置lockkey，程序部分使用try finally。finally中最后判断当前redis中lockKey的value是否和当前线程的UUID一致，如果一致就释放锁。
```
  String clientID= java.util.UUID.randomUUID().toString();
  //set和expire的结合
  Boolean result = redisTemplate.opsForValue().setIfAbsent(lockKey, clientID, 10, TimeUnit.SECONDS);
  //没有这把锁,直接返回
  if(!result){
      return "return";
  }
  try{
      int stock = Integer.parseInt(redisTemplate.opsForValue().get("stock").toString());

      if(stock>0){
          //库存大于0操作
      }else {
          return "库存不足";
      }
  }finally {
      //删除
      if(clientID.equals(redisTemplate.opsForValue().get(lockKey))){
          redisTemplate.delete(lockKey);
      }

  }
```
上述方案已经保证良好的并发性，但是还是会出现锁失效问题。即如果当前线程的执行期间Redis服务器宕机，那么死锁时间就会长，程序等待时间过长。  
**解决方案**为：在当前线程拿到锁之后开启分线程，分线程里开启定时器Timer,判断当前Redis中自家线程的锁是否存在，如果存在那么就延长过期时间。  
  
上述的方案都是自己造轮子，其实可采用**Redission**简单快捷实现Redis高并发的分布式锁
